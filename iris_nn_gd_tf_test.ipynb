{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load iris_nn_gd_tf_test.py\n",
    "# Copyright (c) 2016-2017, Deogtae Kim & DTWARE Inc. All rights reserved.\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\"\n",
    "# del os.environ[\"CUDA_VISIBLE_DEVICES\"]\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(107)\n",
    "\n",
    "## 데이터 수집\n",
    "\n",
    "dataset = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([210, 105], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 훈련 데이터와 테스트 데이터로 분할\n",
    "X_data = dataset.data\n",
    "y_data = dataset.target\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y_data = np.asarray(label_binarize(y_data, [0, 1, 2]), dtype=np.float64)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_data, y_data, test_size = .3, random_state=101, stratify=y_data)  \n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 예측 모델 정의: 소프트맥스 회귀 모델 (RELU)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4])\n",
    "Y = tf.placeholder(tf.float32, [None, 3])\n",
    "W1 = tf.Variable(tf.random_uniform([4,100], -1.0, 1.0))     # 원래 4*3 이었는데 4*100으로 바꿈. 히든레이어 층에 100개가 됨.   \n",
    "b1 = tf.Variable(tf.zeros([100]))                           # 바이어스도 100개로.\n",
    "h = tf.nn.relu(tf.matmul(X, W1) + b1)                       # N*100개 벡터생성 \n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([100,3], -1.0, 1.0))\n",
    "b2 = tf.Variable(tf.zeros([3]))\n",
    "# 각 데이터에 대한 각 분류별 점수\n",
    "score = tf.matmul(h, W2) + b2\n",
    "\n",
    "pred = tf.nn.softmax(score)\n",
    "\n",
    "## 손실 함수, 정확도, 최적화 함수 정의\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(pred), reduction_indices=[1]))\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0100 cost = 0.457220972 , accuacy =  0.822222233\n",
      "Epoch: 0200 cost = 0.077519700 , accuacy =  0.955555558\n",
      "Epoch: 0300 cost = 0.070968963 , accuacy =  0.955555558\n",
      "Epoch: 0400 cost = 0.066194929 , accuacy =  0.955555558\n",
      "Epoch: 0500 cost = 0.062356114 , accuacy =  0.955555558\n",
      "Epoch: 0600 cost = 0.059183273 , accuacy =  0.955555558\n",
      "Epoch: 0700 cost = 0.056507364 , accuacy =  0.955555558\n",
      "Epoch: 0800 cost = 0.054215264 , accuacy =  0.955555558\n",
      "Epoch: 0900 cost = 0.052226260 , accuacy =  0.955555558\n",
      "Epoch: 1000 cost = 0.050481256 , accuacy =  0.955555558\n",
      "훈련 시간: 1.8025267124176025\n",
      "[[7.5781799e-04 9.3836081e-01 6.0881361e-02]\n",
      " [9.9764472e-01 2.3552172e-03 3.3895123e-10]\n",
      " [1.0585560e-03 9.9814260e-01 7.9890055e-04]\n",
      " [1.9074009e-06 2.0735806e-02 9.7926235e-01]]\n",
      "혼돈 행렬:\n",
      "[[35  0  0]\n",
      " [ 0 34  1]\n",
      " [ 0  0 35]]\n"
     ]
    }
   ],
   "source": [
    "## 훈련\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "import time\n",
    "start = time.time()\n",
    "for epoch in range(1000):\n",
    "    c, _  = sess.run([cost, train_step], feed_dict={X: X_train, Y: y_train})\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(c), \n",
    "              ', accuacy = ', '{:.9f}'.format(sess.run(accuracy, feed_dict={X: X_test, Y: y_test})))\n",
    "print(\"훈련 시간:\", time.time() - start)  \n",
    "\n",
    "## 모델 평가\n",
    "pred2 = sess.run(pred, feed_dict={X: X_train, Y: y_train})\n",
    "print(pred2[0:4,])\n",
    "print(\"혼돈 행렬:\", metrics.confusion_matrix(np.argmax(y_train, axis=1), np.argmax(pred2, axis=1)), sep=\"\\n\")\n",
    "#sess.close()\n",
    "\n",
    "## 모델 평가2\n",
    "pred3 = sess.run(pred, feed_dict={X: X_test, Y: y_test})\n",
    "print(pred3[0:4,])\n",
    "print(\"혼돈 행렬:\", metrics.confusion_matrix(np.argmax(y_test, axis=1), np.argmax(pred3, axis=1)), sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과를 보면 1이 하나 있으므로 예측값과 실제값이 다른 경우가 딱 한번 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
